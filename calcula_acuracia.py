import pandas as pd
from sklearn.metrics import classification_report, accuracy_score

# === 1. Carregar o arquivo com prediÃ§Ãµes feitas pelo modelo ===
df_predito = pd.read_csv("resultado_predito_randomforest.csv", sep=';', decimal=',')

# === 2. Carregar o gabarito (arquivo com a coluna Label real) ===
df_gabarito = pd.read_csv("dados_misturados_para_teste_da_randomforest_labeled_trafego_variado_v2.csv", sep=';', decimal=',')

# === 3. Garantir que as linhas estÃ£o alinhadas ===
if len(df_predito) != len(df_gabarito):
    raise ValueError("âŒ Os arquivos tÃªm quantidade diferente de linhas!")

# === 4. Comparar as prediÃ§Ãµes com o gabarito ===
y_true = df_gabarito['Label']
y_pred = df_predito['is_attack?']

# === 5. Exibir resultado ===
print("âœ… RelatÃ³rio de ClassificaÃ§Ã£o (Comparando com Gabarito):\n")
print(classification_report(y_true, y_pred))

# AcurÃ¡cia bruta
print(f"ğŸ¯ AcurÃ¡cia: {accuracy_score(y_true, y_pred) * 100:.2f}%")
